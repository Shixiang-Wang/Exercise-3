{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"tensorflow-text==2.12.0\" # Very important!\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text"
      ],
      "metadata": {
        "id": "F2_nmCrEeIJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"Ethos_Dataset_Binary.csv\", sep=\";\")\n",
        "\n",
        "# Data Processing\n",
        "# Convert pandas dataframe to numpy array\n",
        "data = df.to_numpy()\n",
        "\n",
        "# Extract comments from column 0\n",
        "comments = data[:, 0]\n",
        "\n",
        "# Extract labels from column 1\n",
        "labels = data[:, 1]"
      ],
      "metadata": {
        "id": "5Rs8nhJUeL6S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore Dataset\n",
        "\n",
        "# Histogram of labels\n",
        "plt.hist(labels, color=\"steelblue\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Hate Speech Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Dichotomize labels (hate speech: 0 = no, 1 = yes)\n",
        "# Decision criterion: Hate speech if minimum 50% of reviewers rated the comment as hate speech\n",
        "labels[labels >= 0.5] = 1\n",
        "labels[labels < 0.5] = 0\n",
        "labels = labels.astype(int)\n",
        "\n",
        "# Histogram of binary labels\n",
        "plt.hist(labels, color=\"steelblue\", edgecolor=\"black\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Hate Speech Binary Labels\")\n",
        "plt.show()\n",
        "\n",
        "# Label frequencies\n",
        "num_hate_comments = len(labels[labels == 1])\n",
        "num_no_hate_comments = len(labels[labels == 0])\n",
        "percent_hate_comments = np.round(num_hate_comments/len(labels)*100,2)\n",
        "percent_no_hate_comments = np.round(num_no_hate_comments/len(labels)*100,2)\n",
        "print(\"Number of hate speech comments\")\n",
        "print(f\"Hate speech: {num_hate_comments} comments ({percent_hate_comments}%)\")\n",
        "print(f\"No Hate Speech: {num_no_hate_comments} comments ({percent_no_hate_comments}%)\")\n",
        "print(\"=\"*20)\n",
        "\n",
        "# Display first 10 comments\n",
        "print(\"Here are 10 example comments.\")\n",
        "for i in range(10):\n",
        "    print(f\"Comment {i+1}: {comments[i]}\")\n",
        "print(\"=\"*20)"
      ],
      "metadata": {
        "id": "Buxipm-TeVY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Building\n",
        "\n",
        "# Split dataset into training and test data\n",
        "comments_train, comments_test, labels_train, labels_test = train_test_split(\n",
        "    comments, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize instance for early stopping (used in all models)\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    patience=20,\n",
        "    restore_best_weights=True)\n",
        "\n",
        "# Specify dropout rate (used in all models)\n",
        "dropout_rate = 0.5"
      ],
      "metadata": {
        "id": "YE76jSO_eWEx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: SimpleRNN\n",
        "import os\n",
        "# Initialize tokenizer\n",
        "num_words = 5000  # maximum number of unique words in the dictionary of the tokenizer\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    num_words=num_words,\n",
        "    filters='\"!#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True, split=\" \", char_level=False, oov_token=None)\n",
        "\n",
        "# Fit tokenizer to training data\n",
        "tokenizer.fit_on_texts(comments_train)\n",
        "\n",
        "# Save dictionary\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Display first 100 words of the dictionary\n",
        "count = 0\n",
        "for key, value in word_index.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "    count += 1\n",
        "    if count == 100:\n",
        "        break\n",
        "\n",
        "# Apply tokenizer to training and test data\n",
        "sequences_train = tokenizer.texts_to_sequences(comments_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(comments_test)\n",
        "\n",
        "# Display first 5 sequences\n",
        "print(sequences_train[:5])\n",
        "\n",
        "# Apply sequence padding to obtain consistent sequence length\n",
        "max_length = 15\n",
        "padded_sequences_train = keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences_train,\n",
        "    maxlen=max_length,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "    )\n",
        "padded_sequences_test = keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences_test,\n",
        "    maxlen=max_length,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Display first 5 padded sequences\n",
        "print(padded_sequences_train[:5])\n",
        "\n",
        "# Specify the number of dimensions of the word vectors in the embedding layer\n",
        "word_vector_dim = 50\n",
        "\n",
        "# Specify model\n",
        "model1 = keras.models.Sequential()\n",
        "model1.add(keras.layers.Embedding(num_words+1,  # number of words in tokenizer +1 for the \"0\" used for padding\n",
        "                                  word_vector_dim,\n",
        "                                  input_length=max_length,\n",
        "                                  mask_zero=True))\n",
        "model1.add(keras.layers.SimpleRNN(128,\n",
        "                                  return_sequences=True,\n",
        "                                  dropout=dropout_rate,\n",
        "                                  recurrent_dropout=dropout_rate))\n",
        "model1.add(keras.layers.SimpleRNN(128,\n",
        "                                  dropout=dropout_rate,\n",
        "                                  recurrent_dropout=dropout_rate))\n",
        "model1.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "model1.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Summarize model\n",
        "model1.summary()\n",
        "\n",
        "# Compile model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model1.compile(optimizer=optimizer,\n",
        "               loss=\"binary_crossentropy\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model1_history = model1.fit(padded_sequences_train, labels_train,\n",
        "                            epochs=100, batch_size=8,\n",
        "                            validation_data=(padded_sequences_test, labels_test),\n",
        "                            callbacks=early_stopping)\n",
        "\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "# Save model\n",
        "model1.save(\"saved_models/model1.keras\")\n",
        "\n",
        "# Load model\n",
        "model1 = keras.models.load_model(\"saved_models/model1.keras\")\n",
        "\n",
        "# Learning curve: Loss\n",
        "plt.plot(model1_history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(model1_history.history[\"val_loss\"], label=\"Test Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Learning curve: Accuracy\n",
        "plt.plot(model1_history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(model1_history.history[\"val_accuracy\"], label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate model: Accuracy for training and test data\n",
        "train_score_model1 = model1.evaluate(padded_sequences_train, labels_train)\n",
        "test_score_model1 = model1.evaluate(padded_sequences_test, labels_test)\n",
        "print(\"Accuracy Train data: \", train_score_model1[1])\n",
        "print(\"Accuracy Test data: \", test_score_model1[1])\n",
        "\n",
        "# Predicted labels for test data\n",
        "labels_pred_prob_model1 = model1.predict(padded_sequences_test)\n",
        "labels_pred_model1 = labels_pred_prob_model1.copy()\n",
        "labels_pred_model1[labels_pred_model1 >= 0.5] = 1\n",
        "labels_pred_model1[labels_pred_model1 < 0.5] = 0\n",
        "\n",
        "# Evaluate model: Classification report for test data\n",
        "print(\"Classification Report: Model 1 (SimpleRNN)\")\n",
        "print(classification_report(labels_test, labels_pred_model1))\n",
        "\n",
        "# Evaluate model: Confusion matrix for test data\n",
        "cm = confusion_matrix(labels_test, labels_pred_model1)\n",
        "cm_disp = ConfusionMatrixDisplay(cm)\n",
        "cm_disp.plot()\n",
        "\n",
        "# Illustrative examples: True vs. predicted labels for clear and obvious hate speech\n",
        "for i in [236, 207, 15, 29, 183]:\n",
        "    print(f\"Comment: {comments_test[i]}\")\n",
        "    print(f\"True label: {labels_test[i]}\")\n",
        "    print(f\"Predicted label: {int(labels_pred_model1[i][0])}\")\n",
        "    print(\"===\")"
      ],
      "metadata": {
        "id": "sV4dSAxEeYkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: LSTM\n",
        "\n",
        "\n",
        "# Initialize tokenizer\n",
        "num_words = 5000  # maximum number of unique words in the dictionary of the tokenizer\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(\n",
        "    num_words=num_words,\n",
        "    filters='\"!#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True, split=\" \", char_level=False, oov_token=None)\n",
        "\n",
        "# Fit tokenizer to training data\n",
        "tokenizer.fit_on_texts(comments_train)\n",
        "\n",
        "# Apply tokenizer to training and test data\n",
        "sequences_train = tokenizer.texts_to_sequences(comments_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(comments_test)\n",
        "\n",
        "# Apply sequence padding to obtain consistent sequence length\n",
        "max_length = 150\n",
        "padded_sequences_train = keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences_train,\n",
        "    maxlen=max_length,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "    )\n",
        "padded_sequences_test = keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences_test,\n",
        "    maxlen=max_length,\n",
        "    truncating=\"post\",\n",
        "    padding=\"post\"\n",
        "    )\n",
        "\n",
        "# Specify the number of dimensions of the word vectors in the embedding layer\n",
        "word_vector_dim = 50\n",
        "\n",
        "# Specify model\n",
        "model2 = keras.models.Sequential()\n",
        "model2.add(keras.layers.Embedding(num_words+1,  # number of words in tokenizer +1 for the \"0\" used for padding\n",
        "                                  word_vector_dim,\n",
        "                                  input_length=max_length,\n",
        "                                  mask_zero=True))\n",
        "model2.add(keras.layers.LSTM(128,\n",
        "                             return_sequences=True,\n",
        "                             dropout=dropout_rate,\n",
        "                             recurrent_dropout=dropout_rate))\n",
        "model2.add(keras.layers.LSTM(128,\n",
        "                             dropout=dropout_rate,\n",
        "                             recurrent_dropout=dropout_rate))\n",
        "model2.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "model2.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Summarize model\n",
        "model2.summary()\n",
        "\n",
        "# Compile model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model2.compile(optimizer=optimizer,\n",
        "               loss=\"binary_crossentropy\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model2_history = model2.fit(padded_sequences_train, labels_train,\n",
        "                            epochs=100, batch_size=32,\n",
        "                            validation_data=(padded_sequences_test, labels_test),\n",
        "                            callbacks=early_stopping)\n",
        "\n",
        "# Save model\n",
        "model2.save(\"saved_models/model2.keras\")\n",
        "\n",
        "# Load model\n",
        "model2 = keras.models.load_model(\"saved_models/model2.keras\")\n",
        "\n",
        "# Learning curve: Loss\n",
        "plt.plot(model2_history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(model2_history.history[\"val_loss\"], label=\"Test Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Learning curve: Accuracy\n",
        "plt.plot(model2_history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(model2_history.history[\"val_accuracy\"], label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate model: Accuracy for training and test data\n",
        "train_score_model2 = model2.evaluate(padded_sequences_train, labels_train)\n",
        "test_score_model2 = model2.evaluate(padded_sequences_test, labels_test)\n",
        "print(\"Accuracy Train data: \", train_score_model2[1])\n",
        "print(\"Accuracy Test data: \", test_score_model2[1])\n",
        "\n",
        "# Predicted labels for test data\n",
        "labels_pred_prob_model2 = model2.predict(padded_sequences_test)\n",
        "labels_pred_model2 = labels_pred_prob_model2.copy()\n",
        "labels_pred_model2[labels_pred_model2 >= 0.5] = 1\n",
        "labels_pred_model2[labels_pred_model2 < 0.5] = 0\n",
        "\n",
        "# Evaluate model: Classification report for test data\n",
        "print(\"Classification Report: Model 2 (LSTM)\")\n",
        "print(classification_report(labels_test, labels_pred_model2))\n",
        "\n",
        "# Evaluate model: Confusion matrix for test data\n",
        "cm = confusion_matrix(labels_test, labels_pred_model2)\n",
        "cm_disp = ConfusionMatrixDisplay(cm)\n",
        "cm_disp.plot()\n",
        "\n",
        "# Illustrative examples: True vs. predicted labels for clear and obvious hate speech\n",
        "for i in [236, 207, 15, 29, 183]:\n",
        "    print(f\"Comment: {comments_test[i]}\")\n",
        "    print(f\"True label: {labels_test[i]}\")\n",
        "    print(f\"Predicted label: {int(labels_pred_model2[i][0])}\")\n",
        "    print(\"===\")"
      ],
      "metadata": {
        "id": "HgLy8jfheabV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3: BERT\n",
        "\n",
        "# Specify the input layer\n",
        "text_input = keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "\n",
        "# Preprocess the text inputs using the BERT preprocessing layer\n",
        "preprocessor = hub.KerasLayer(\"https://www.kaggle.com/models/tensorflow/bert/tensorFlow2/en-uncased-preprocess/3?tfhub-redirect=true\",\n",
        "                              name=\"preprocessing\")\n",
        "preprocessed_inputs = preprocessor(text_input)\n",
        "\n",
        "# Load the BERT model\n",
        "bert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/2\",\n",
        "                      trainable=True,\n",
        "                      name=\"BERT\")\n",
        "\n",
        "# Pass the preprocessed text inputs through the BERT model\n",
        "bert_outputs = bert(preprocessed_inputs)\n",
        "\n",
        "# Extract the pooled output from the BERT outputs\n",
        "pooled_bert_output = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "# Apply dropout regularization\n",
        "pooled_bert_output = keras.layers.Dropout(dropout_rate)(pooled_bert_output)\n",
        "\n",
        "# Fine-tune the BERT model with dense layers for the hate speech detection task\n",
        "dense = keras.layers.Dense(128, activation=\"relu\")(pooled_bert_output)\n",
        "outputs = keras.layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(dense)\n",
        "\n",
        "# Create model\n",
        "model3 = keras.Model(inputs=text_input, outputs=outputs)\n",
        "\n",
        "# Summarize model\n",
        "model3.summary()\n",
        "\n",
        "# Compile model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model3.compile(optimizer=optimizer,\n",
        "               loss=\"binary_crossentropy\",\n",
        "               metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit model\n",
        "model3_history = model3.fit(comments_train, labels_train,\n",
        "                            epochs=100, batch_size=8,\n",
        "                            validation_data=(comments_test, labels_test),\n",
        "                            callbacks=early_stopping)\n",
        "\n",
        "# Save model\n",
        "model3.save(\"saved_models/model3.keras\")\n",
        "\n",
        "# Load model\n",
        "model3 = keras.models.load_model(\"saved_models/model3.keras\", custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "# Learning curve: Loss\n",
        "plt.plot(model3_history.history[\"loss\"], label=\"Train Loss\")\n",
        "plt.plot(model3_history.history[\"val_loss\"], label=\"Test Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Learning curve: Accuracy\n",
        "plt.plot(model3_history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(model3_history.history[\"val_accuracy\"], label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate model: Accuracy for training and test data\n",
        "train_score_model3 = model3.evaluate(comments_train, labels_train)\n",
        "test_score_model3 = model3.evaluate(comments_test, labels_test)\n",
        "print(\"Accuracy Train data: \", train_score_model3[1])\n",
        "print(\"Accuracy Test data: \", test_score_model3[1])\n",
        "\n",
        "# Predicted labels for test data\n",
        "labels_pred_prob_model3 = model3.predict(comments_test)\n",
        "labels_pred_model3 = labels_pred_prob_model3.copy()\n",
        "labels_pred_model3[labels_pred_model3 >= 0.5] = 1\n",
        "labels_pred_model3[labels_pred_model3 < 0.5] = 0\n",
        "\n",
        "# Evalute model: Classification report for test data\n",
        "print(\"Classification Report: Model 3 (Bert)\")\n",
        "print(classification_report(labels_test, labels_pred_model3))\n",
        "\n",
        "# Evaluate model: Confusion matrix for test data\n",
        "cm = confusion_matrix(labels_test, labels_pred_model3)\n",
        "cm_disp = ConfusionMatrixDisplay(cm)\n",
        "cm_disp.plot()\n",
        "\n",
        "# Illustrative examples: True vs. predicted labels for clear and obvious hate speech\n",
        "for i in [236, 207, 15, 29, 183]:\n",
        "    print(f\"Comment: {comments_test[i]}\")\n",
        "    print(f\"True label: {labels_test[i]}\")\n",
        "    print(f\"Predicted label: {int(labels_pred_model3[i][0])}\")\n",
        "    print(\"===\")"
      ],
      "metadata": {
        "id": "H6JsqeZcechE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
